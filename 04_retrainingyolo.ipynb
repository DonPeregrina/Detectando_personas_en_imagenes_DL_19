{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"},"colab":{"name":"04_retrainingyolo.ipynb","version":"0.3.2","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"R27aCTVLbXvl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":127},"outputId":"dce174dc-cc03-4693-dda8-e17fe24eba4f","executionInfo":{"status":"ok","timestamp":1566932156551,"user_tz":300,"elapsed":44021,"user":{"displayName":"Actumlogos","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBl0f3JAptHOoOvgnBFKE7NeTyhOTFgjcG_1EWw=s64","userId":"08137321615727507295"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mYUTCegwbr01","colab_type":"code","colab":{}},"source":["import shutil, zipfile\n","\n","filename = 'dataset_intrusos.zip'\n","shutil.copy(\"drive/My Drive/Material/\" + filename, \"./\" + filename)\n","zip_ref = zipfile.ZipFile(filename, 'r')\n","zip_ref.extractall()\n","zip_ref.close()\n","\n","filename = 'detector.zip'\n","shutil.copy(\"drive/My Drive/Material/\" + filename, \"./\" + filename)\n","zip_ref = zipfile.ZipFile(filename, 'r')\n","zip_ref.extractall()\n","zip_ref.close()\n","\n","# Subir el archivo dataset_intrusos.txt obtenido anteriormente"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4pgOn3feHtJv","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","def get_classes(classes_path):\n","    '''loads the classes'''\n","    with open(classes_path) as f:\n","        class_names = f.readlines()\n","    class_names = [c.strip() for c in class_names]\n","    return class_names\n","\n","def get_anchors(anchors_path):\n","    '''loads the anchors from a file'''\n","    with open(anchors_path) as f:\n","        anchors = f.readline()\n","    anchors = [float(x) for x in anchors.split(',')]\n","    return np.array(anchors).reshape(-1, 2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L33wIHa-HtJy","colab_type":"code","outputId":"c734112f-ad34-4317-98cf-a51756c38f60","executionInfo":{"status":"ok","timestamp":1566932215005,"user_tz":300,"elapsed":1950,"user":{"displayName":"Actumlogos","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBl0f3JAptHOoOvgnBFKE7NeTyhOTFgjcG_1EWw=s64","userId":"08137321615727507295"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from detector.utils import get_random_data\n","from detector.model import preprocess_true_boxes\n","\n","def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n","    '''data generator for fit_generator'''\n","    n = len(annotation_lines)\n","    i = 0\n","    while True:\n","        image_data = []\n","        box_data = []\n","        for b in range(batch_size):\n","            if i==0:\n","                np.random.shuffle(annotation_lines)\n","            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n","            image_data.append(image)\n","            box_data.append(box)\n","            i = (i+1) % n\n","        image_data = np.array(image_data)\n","        box_data = np.array(box_data)\n","        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n","        yield [image_data, *y_true], np.zeros(batch_size)\n","\n","def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n","    n = len(annotation_lines)\n","    if n==0 or batch_size<=0: return None\n","    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"MxrtOQTDHtJ2","colab_type":"code","colab":{}},"source":["def create_tiny_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n","            weights_path='detector/yolo-tiny.h5'):\n","    '''create the training model, for Tiny YOLOv3'''\n","    K.clear_session() # get a new session\n","    image_input = Input(shape=(None, None, 3))\n","    h, w = input_shape\n","    num_anchors = len(anchors)\n","\n","    y_true = [Input(shape=(h//{0:32, 1:16}[l], w//{0:32, 1:16}[l], \\\n","        num_anchors//2, num_classes+5)) for l in range(2)]\n","\n","    model_body = tiny_yolo_body(image_input, num_anchors//2, num_classes)\n","    print('Create Tiny YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n","\n","    if load_pretrained:\n","        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n","        print('Load weights {}.'.format(weights_path))\n","        if freeze_body in [1, 2]:\n","            # Freeze the darknet body or freeze all but 2 output layers.\n","            num = (20, len(model_body.layers)-2)[freeze_body-1]\n","            for i in range(num): model_body.layers[i].trainable = False\n","            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n","\n","    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n","        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.7})(\n","        [*model_body.output, *y_true])\n","    model = Model([model_body.input, *y_true], model_loss)\n","\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RtCMGNgxHtJ4","colab_type":"code","colab":{}},"source":["import keras.backend as K\n","from keras.layers import Input, Lambda\n","from keras.models import Model\n","\n","from detector.model import yolo_body, tiny_yolo_body, yolo_loss\n","\n","def create_model(input_shape, anchors, num_classes, load_pretrained=True, \n","                 freeze_body=2,\n","                weights_path='/yolov3.h5'):\n","    K.clear_session() \n","    image_input = Input(shape=(None, None, 3))\n","    h, w = input_shape\n","    num_anchors = len(anchors)\n","\n","    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n","        num_anchors//3, num_classes+5)) for l in range(3)]\n","\n","    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n","    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n","\n","    if load_pretrained:\n","        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n","        print('Load weights {}.'.format(weights_path))\n","        if freeze_body in [1, 2]:\n","            # Freeze darknet53 body or freeze all but 3 output layers.\n","            num = (185, len(model_body.layers)-3)[freeze_body-1]\n","            for i in range(num): model_body.layers[i].trainable = False\n","            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n","\n","    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n","        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n","        [*model_body.output, *y_true])\n","    model = Model([model_body.input, *y_true], model_loss)\n","\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"Khx0dZvYHtJ6","colab_type":"code","outputId":"27944c59-ad9d-4600-dfa0-d5c4c3d0f21c","executionInfo":{"status":"ok","timestamp":1566932682123,"user_tz":300,"elapsed":450878,"user":{"displayName":"Actumlogos","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBl0f3JAptHOoOvgnBFKE7NeTyhOTFgjcG_1EWw=s64","userId":"08137321615727507295"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from keras.optimizers import Adam\n","from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n","\n","annotation_path = 'dataset_intrusos.txt'\n","log_dir = 'logs/000/'\n","classes_path = 'detector/coco_classes.txt'\n","anchors_path = 'detector/tiny_yolo_anchors.txt'\n","class_names = get_classes(classes_path)\n","num_classes = len(class_names)\n","anchors = get_anchors(anchors_path)\n","\n","input_shape = (416,416) # multiple of 32, hw\n","\n","is_tiny_version = len(anchors)==6 # default setting\n","if is_tiny_version:\n","    model = create_tiny_model(input_shape, anchors, num_classes,\n","        freeze_body=2, weights_path='detector/yolo-tiny.h5')\n","else:\n","    model = create_model(input_shape, anchors, num_classes,\n","        freeze_body=2, weights_path='detector/yolov3.h5') # make sure you know what you freeze\n","\n","logging = TensorBoard(log_dir=log_dir)\n","checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n","    monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n","early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n","\n","val_split = 0.1\n","with open(annotation_path) as f:\n","    lines = f.readlines()\n","np.random.seed(10101)\n","np.random.shuffle(lines)\n","np.random.seed(None)\n","num_val = int(len(lines)*val_split)\n","num_train = len(lines) - num_val\n","\n","# Train with frozen layers first, to get a stable loss.\n","# Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n","if True:\n","    model.compile(optimizer=Adam(lr=1e-3), loss={\n","        # use custom yolo_loss Lambda layer.\n","        'yolo_loss': lambda y_true, y_pred: y_pred})\n","\n","    batch_size = 32\n","    print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n","    model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n","            steps_per_epoch=max(1, num_train//batch_size),\n","            validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n","            validation_steps=max(1, num_val//batch_size),\n","            epochs=20,\n","            initial_epoch=0,\n","            callbacks=[logging, checkpoint])\n","    model.save_weights(log_dir + 'trained_weights_stage_1.h5')\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0827 18:57:11.451372 139777800742784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n","\n","W0827 18:57:11.452910 139777800742784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","W0827 18:57:11.499704 139777800742784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0827 18:57:11.500821 139777800742784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0827 18:57:11.510042 139777800742784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0827 18:57:14.945910 139777800742784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","W0827 18:57:15.032475 139777800742784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","W0827 18:57:16.009289 139777800742784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Create Tiny YOLOv3 model with 6 anchors and 80 classes.\n"],"name":"stdout"},{"output_type":"stream","text":["W0827 18:57:16.882143 139777800742784 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3080: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Load weights detector/yolo-tiny.h5.\n","Freeze the first 42 layers of total 44 layers.\n"],"name":"stdout"},{"output_type":"stream","text":["W0827 18:57:19.633275 139777800742784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 315 samples, val on 35 samples, with batch size 32.\n"],"name":"stdout"},{"output_type":"stream","text":["W0827 18:57:20.605774 139777800742784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n","\n","W0827 18:57:20.608975 139777800742784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","9/9 [==============================] - 34s 4s/step - loss: 11.7470 - val_loss: 8.8115\n","Epoch 2/20\n","9/9 [==============================] - 23s 3s/step - loss: 9.9992 - val_loss: 9.3681\n","Epoch 3/20\n","9/9 [==============================] - 21s 2s/step - loss: 9.9110 - val_loss: 10.1507\n","Epoch 4/20\n","9/9 [==============================] - 20s 2s/step - loss: 9.2482 - val_loss: 8.1074\n","Epoch 5/20\n","9/9 [==============================] - 21s 2s/step - loss: 8.7387 - val_loss: 9.0445\n","Epoch 6/20\n","9/9 [==============================] - 21s 2s/step - loss: 8.5268 - val_loss: 8.3234\n","Epoch 7/20\n","9/9 [==============================] - 21s 2s/step - loss: 9.3169 - val_loss: 7.8753\n","Epoch 8/20\n","9/9 [==============================] - 21s 2s/step - loss: 8.6838 - val_loss: 9.2517\n","Epoch 9/20\n","9/9 [==============================] - 21s 2s/step - loss: 8.1431 - val_loss: 7.0333\n","Epoch 10/20\n","9/9 [==============================] - 21s 2s/step - loss: 8.1663 - val_loss: 9.1459\n","Epoch 11/20\n","9/9 [==============================] - 21s 2s/step - loss: 8.3141 - val_loss: 8.9403\n","Epoch 12/20\n","9/9 [==============================] - 21s 2s/step - loss: 8.6549 - val_loss: 8.5758\n","Epoch 13/20\n","9/9 [==============================] - 21s 2s/step - loss: 8.0220 - val_loss: 7.1002\n","Epoch 14/20\n","9/9 [==============================] - 22s 2s/step - loss: 8.2636 - val_loss: 8.8717\n","Epoch 15/20\n","9/9 [==============================] - 21s 2s/step - loss: 8.4247 - val_loss: 8.6957\n","Epoch 16/20\n","9/9 [==============================] - 21s 2s/step - loss: 7.5428 - val_loss: 7.4650\n","Epoch 17/20\n","9/9 [==============================] - 21s 2s/step - loss: 7.7021 - val_loss: 8.7936\n","Epoch 18/20\n","9/9 [==============================] - 21s 2s/step - loss: 8.1746 - val_loss: 7.4548\n","Epoch 19/20\n","9/9 [==============================] - 21s 2s/step - loss: 7.9452 - val_loss: 8.4884\n","Epoch 20/20\n","9/9 [==============================] - 21s 2s/step - loss: 7.6916 - val_loss: 7.1264\n"],"name":"stdout"}]}]}